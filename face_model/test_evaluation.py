#!/usr/bin/env python3
"""
Test script for Face ID Model evaluation
"""

import torch
import os
import sys
sys.path.append('.')

from evaluate_face_id import FaceIDEvaluator

def test_evaluation_setup():
    """Test if evaluation setup works"""
    
    # Check for checkpoint
    checkpoint_path = "/Users/ozgewhiting/Documents/projects/dataset_utils/checkpoints/face_id_epoch_3.pth"
    data_dir = "/Users/ozgewhiting/Documents/EQLabs/datasets_serial/CCA_test_db1"
    
    print("ğŸ” Testing Face ID Model Evaluation Setup")
    print(f"ğŸ“ Checkpoint: {checkpoint_path}")
    print(f"ğŸ“Š Dataset: {data_dir}")
    
    # Check if checkpoint exists
    if not os.path.exists(checkpoint_path):
        print(f"âŒ Checkpoint not found: {checkpoint_path}")
        print("Please train the model first or update the checkpoint path.")
        return False
    
    print("âœ… Checkpoint found")
    
    # Check if dataset exists
    if not os.path.exists(data_dir):
        print(f"âŒ Dataset not found: {data_dir}")
        return False
    
    print("âœ… Dataset found")
    
    # Test evaluator initialization
    try:
        evaluator = FaceIDEvaluator(checkpoint_path, data_dir)
        print("âœ… Evaluator initialized successfully")
        
        # Test with a small sample
        print("\nğŸ§ª Testing with 5 samples...")
        results = evaluator.run_evaluation(max_samples=5)
        
        print("âœ… Evaluation test completed successfully!")
        print(f"ğŸ“Š Processed {len(results['identity_tokens'])} samples")
        print(f"ğŸ‘¥ Unique subjects: {len(set(results['subject_ids']))}")
        print(f"ğŸ“ˆ Average consistency: {sum(results['frame_consistencies'])/len(results['frame_consistencies']):.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Evaluation test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_evaluation_setup() 